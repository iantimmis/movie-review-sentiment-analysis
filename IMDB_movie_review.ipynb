{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis on IMDB movie reviews using GloVe embeddings and deep LSTM network\n",
    "\n",
    "This is a draft only showing the ability to convert an example of an IMDB movie review into a vectorized representation using a 50-dimensional GloVe word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load 50 dimensional word embedding matrix (GloVe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file, 'r', encoding=\"utf8\") as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_path = \"C:/Users/ianti_000/Desktop/imdb_sentiment_analysis/glove.6B/glove.6B.50d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_index, index_to_words, word_to_vec_map = read_glove_vecs(glove_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embedding Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scientist \n",
      " [-0.1574     0.60965    0.33007    0.099683   0.48562    0.047824  -0.73879\n",
      " -0.53599    0.32418    0.12761    0.59657    0.40019    0.04229    0.67915\n",
      "  0.17035   -0.0092601  0.5116     0.87818   -0.69902    0.89466   -0.12511\n",
      "  0.82933    0.12066   -0.27192    1.0609    -2.2313    -0.52398   -0.88116\n",
      " -1.0067     0.65938    0.92674   -1.8196    -0.71182   -1.4838    -0.2425\n",
      " -0.070873  -0.66168    0.93268    1.1923     0.10765    0.39583    0.60167\n",
      "  0.21796    0.021389   1.2813    -0.0055883  0.25846    0.45233   -0.11514\n",
      "  0.54043  ]\n"
     ]
    }
   ],
   "source": [
    "word = \"scientist\"\n",
    "try:\n",
    "    print(word,'\\n', word_to_vec_map[word])\n",
    "except:\n",
    "    print(word, \" not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert training example into vectorized version using word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  121  words in this example\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['story',\n",
       " 'of',\n",
       " 'a',\n",
       " 'man',\n",
       " 'who',\n",
       " 'has',\n",
       " 'unnatural',\n",
       " 'feelings',\n",
       " 'for',\n",
       " 'a',\n",
       " 'pig',\n",
       " '.',\n",
       " 'starts',\n",
       " 'out',\n",
       " 'with',\n",
       " 'a',\n",
       " 'opening',\n",
       " 'scene',\n",
       " 'that',\n",
       " 'is',\n",
       " 'a',\n",
       " 'terrific',\n",
       " 'example',\n",
       " 'of',\n",
       " 'absurd',\n",
       " 'comedy',\n",
       " '.',\n",
       " 'a',\n",
       " 'formal',\n",
       " 'orchestra',\n",
       " 'audience',\n",
       " 'is',\n",
       " 'turned',\n",
       " 'into',\n",
       " 'an',\n",
       " 'insane',\n",
       " ',',\n",
       " 'violent',\n",
       " 'mob',\n",
       " 'by',\n",
       " 'the',\n",
       " 'crazy',\n",
       " 'chantings',\n",
       " 'of',\n",
       " 'its',\n",
       " 'singers',\n",
       " '.',\n",
       " 'unfortunately',\n",
       " 'it',\n",
       " 'stays',\n",
       " 'absurd',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'time',\n",
       " 'with',\n",
       " 'no',\n",
       " 'general',\n",
       " 'narrative',\n",
       " 'eventually',\n",
       " 'making',\n",
       " 'it',\n",
       " 'just',\n",
       " 'too',\n",
       " 'off',\n",
       " 'putting',\n",
       " '.',\n",
       " 'even',\n",
       " 'those',\n",
       " 'from',\n",
       " 'the',\n",
       " 'era',\n",
       " 'should',\n",
       " 'be',\n",
       " 'turned',\n",
       " 'off',\n",
       " '.',\n",
       " 'the',\n",
       " 'cryptic',\n",
       " 'dialogue',\n",
       " 'would',\n",
       " 'make',\n",
       " 'shakespeare',\n",
       " 'seem',\n",
       " 'easy',\n",
       " 'to',\n",
       " 'a',\n",
       " 'third',\n",
       " 'grader',\n",
       " '.',\n",
       " 'on',\n",
       " 'a',\n",
       " 'technical',\n",
       " 'level',\n",
       " 'its',\n",
       " 'better',\n",
       " 'than',\n",
       " 'you',\n",
       " 'might',\n",
       " 'think',\n",
       " 'with',\n",
       " 'some',\n",
       " 'good',\n",
       " 'cinematography',\n",
       " 'by',\n",
       " 'future',\n",
       " 'great',\n",
       " 'vilmos',\n",
       " 'zsigmond',\n",
       " '.',\n",
       " 'future',\n",
       " 'stars',\n",
       " 'sally',\n",
       " 'kirkland',\n",
       " 'and',\n",
       " 'frederic',\n",
       " 'forrest',\n",
       " 'can',\n",
       " 'be',\n",
       " 'seen',\n",
       " 'briefly',\n",
       " '.']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read one of the examples\n",
    "negative_example = \"C:/Users/ianti_000/Desktop/imdb_sentiment_analysis/aclImdb_v1/aclImdb/train/neg/0_3.txt\"\n",
    "file = open(negative_example, 'r')\n",
    "words = file.read()\n",
    "\n",
    "# Clean the example, make lowercase, and split into array of words\n",
    "words = words.replace(\"'\",\"\").replace(\",\",\" ,\").replace(\".\",\" .\").lower().split()\n",
    "\n",
    "print(\"There are \", len(words), \" words in this example\")\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chantings  not found\n"
     ]
    }
   ],
   "source": [
    "glove_representation = []\n",
    "\n",
    "for word in words:\n",
    "    try:\n",
    "        glove_representation.append(word_to_vec_map[word])\n",
    "    except:\n",
    "        print(word, \" not found\")\n",
    "glove_representation = np.array(glove_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 50)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_representation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.48251 ,  0.87746 , -0.23455 , ..., -0.4112  ,  0.23625 ,\n",
       "         0.26451 ],\n",
       "       [ 0.70853 ,  0.57088 , -0.4716  , ..., -0.22562 , -0.093918,\n",
       "        -0.80375 ],\n",
       "       [ 0.21705 ,  0.46515 , -0.46757 , ..., -0.043782,  0.41013 ,  0.1796  ],\n",
       "       ..., \n",
       "       [ 0.55561 ,  0.1704  ,  0.13692 , ..., -0.32978 ,  0.24825 ,\n",
       "        -0.38275 ],\n",
       "       [-0.24154 , -0.30059 ,  0.1622  , ..., -1.0468  , -0.52729 ,\n",
       "        -0.60561 ],\n",
       "       [ 0.15164 ,  0.30177 , -0.16763 , ..., -0.35652 ,  0.016413,\n",
       "         0.10216 ]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
